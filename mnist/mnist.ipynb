{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5203d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "n_epochs = 3\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "\n",
    "random_seed = 1\n",
    "## machine does not have cuda\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "    \n",
    "class MnistDataset(Dataset):\n",
    "    def __init__(self, csv_file):\n",
    "\n",
    "        self.frame = pd.read_csv(csv_file)\n",
    "       \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.frame.iloc[idx, 1:]\n",
    "        img = np.array([img]).reshape((28, 28, 1))\n",
    "        img=torchvision.transforms.ToTensor()(img).float()\n",
    "        \n",
    "        label = self.frame.iloc[idx, 0]\n",
    "\n",
    "        return img, label\n",
    "\n",
    "\n",
    "\n",
    "train_dir = \"../mnist/data/mnist_train.csv\"\n",
    "test_dir = \"../mnist/data/mnist_test.csv\"\n",
    "\n",
    "train_dataset = MnistDataset(train_dir)\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=batch_size_train,\n",
    "\n",
    "                          shuffle=True)\n",
    "test_dataset = MnistDataset(test_dir)\n",
    "\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                         batch_size=batch_size_test,\n",
    "\n",
    "                         shuffle=False)\n",
    "\n",
    "examples = enumerate(train_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "for i in range(3):\n",
    "      plt.subplot(1,3,i+1)\n",
    "      plt.tight_layout()\n",
    "      plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "      plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
    "      plt.xticks([])\n",
    "      plt.yticks([])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc632281",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5eb8f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/anaconda3/envs/torch/lib/python3.7/site-packages/ipykernel_launcher.py:17: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 23.857635\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 2.274156\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 2.261950\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 2.316545\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 2.207268\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 1.936084\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 1.855275\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 1.795214\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 1.728762\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 1.360607\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 1.144432\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 1.273558\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 1.463623\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 1.105683\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 1.094131\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 1.148401\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 1.104034\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 1.155020\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 1.056558\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 0.854280\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.795236\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 0.819693\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.654960\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.916749\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.752257\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.820682\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.770986\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.934845\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 1.145236\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.790297\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 1.030327\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.789585\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.756848\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.703191\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.810163\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.758523\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.575045\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.685836\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.921969\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.698897\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.491960\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.502323\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.813733\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.583979\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.544377\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 1.048485\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.887439\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.520376\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.561167\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 1.057690\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.754011\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.531338\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.735185\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.547883\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.492172\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.615527\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.805729\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.576617\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.357977\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.566761\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.767056\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.657739\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.473994\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.614512\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.884970\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.727182\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.464904\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.466359\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.493489\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.522582\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.616418\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.622971\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.475936\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.372801\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.617611\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.608801\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.456860\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.547139\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.506747\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.540504\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.766237\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.541948\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.370990\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.315786\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.604214\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.369804\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.383150\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.511659\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.826371\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.538409\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.519639\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.464893\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.577603\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.268077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/anaconda3/envs/torch/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.1689, Accuracy: 9501/10000 (95%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.422436\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.811711\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.298076\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.432865\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.684991\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.388187\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.527268\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.494035\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.552358\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.442984\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.462331\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.519640\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.303293\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.444019\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.265420\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.577197\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.323071\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.551833\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.380567\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.575090\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.583433\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.258006\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.437176\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.276647\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.598880\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.583688\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.480542\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.565433\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.645619\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.373229\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.521279\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.882848\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.587450\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.313998\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.393692\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.393021\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.426397\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.592372\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.338157\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.428180\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.612731\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.513770\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.531037\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.387612\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.506864\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.386967\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.387570\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.887701\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.497495\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.473969\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.421647\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.687858\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.238607\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.367036\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.560723\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.384269\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.373533\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.455451\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.232319\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.437987\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.258772\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.409798\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.354324\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.425842\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.364098\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.422381\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.415627\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.559945\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.425091\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.474359\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.423469\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.516899\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.292161\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.468239\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.342059\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.502320\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.571971\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.371363\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.204942\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.417358\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.639964\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.681476\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.351793\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.260461\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.390263\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.365528\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.513936\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.424775\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.772915\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.316918\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.499681\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.410878\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.413985\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.356925\n",
      "\n",
      "Test set: Avg. loss: 0.1447, Accuracy: 9571/10000 (96%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.623331\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.170409\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.564512\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.175541\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.537260\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.196389\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.167503\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.371415\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.180039\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.482399\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.406185\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.413113\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.436447\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.481645\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.357968\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.213932\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.440328\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.458078\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.996545\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.410913\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.250101\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.335381\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.378282\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.244598\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.291375\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.322414\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.444178\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.382859\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.360253\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.367490\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.630565\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.476376\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.138859\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.352749\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.659909\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.491347\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.203118\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.579109\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.384294\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.375663\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.335875\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.294464\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.404873\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.354545\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.243009\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.353041\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.462344\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.374093\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.422243\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.340983\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.296040\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.237890\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.399633\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.216785\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.419881\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.410354\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.378836\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.743078\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.420394\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.610598\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.315293\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.552462\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.468892\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.347584\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.356131\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.423706\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.514467\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.673041\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.240792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.303564\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.308043\n",
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.307629\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.431397\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.316955\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.291899\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.151712\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.238296\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.338430\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.412432\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.144561\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.267551\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.289157\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.507820\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.157679\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.557540\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.409872\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.264847\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.464051\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.564618\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.305151\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.248742\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.148593\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.259267\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.383611\n",
      "\n",
      "Test set: Avg. loss: 0.1011, Accuracy: 9677/10000 (97%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def train(epoch):\n",
    "  network.train()\n",
    "  for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    optimizer.zero_grad()\n",
    "    output = network(data)\n",
    "    loss = F.nll_loss(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if batch_idx % log_interval == 0:\n",
    "      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "        epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "        100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "\n",
    "def test():\n",
    "  network.eval()\n",
    "  test_loss = 0\n",
    "  correct = 0\n",
    "  with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "      output = network(data)\n",
    "      test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "      pred = output.data.max(1, keepdim=True)[1]\n",
    "      correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "  test_loss /= len(test_loader.dataset)\n",
    "\n",
    "  print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss, correct, len(test_loader.dataset),\n",
    "    100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "network = NeuralNet()\n",
    "optimizer = optim.SGD(network.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)    \n",
    "for epoch in range(1, n_epochs + 1):\n",
    "  train(epoch)\n",
    "  test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14ee393",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
